{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Embedding Demo\n",
    "This is a demo for for graph embedding utilizing DGLL graph embedding module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get embedding for a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ge.utils import saveEmbedding\n",
    "from ge.deepWalk import DeepWalk\n",
    "from ge.node2vec import Node2vec\n",
    "from ge.struc2vec import Struc2Vec\n",
    "from ge.GDLLGraph import GDLLGraph\n",
    "from ge.skipgram import SkipGramModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = \"cora - copy1.cites\"\n",
    "graph_features = \"cora - copy1.content\"\n",
    "\n",
    "data_dir = \"data/cora\"\n",
    "embedding_dir = \"data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data...\n"
     ]
    }
   ],
   "source": [
    "myGraph = GDLLGraph(data_dir, graph, graph_features = graph_features, sep= \"\\t\").g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedDim = 3 # embedding size\n",
    "numbOfWalksPerVertex = 3 # walks per vertex\n",
    "walkLength = 3# walk length\n",
    "lr =0.25 # learning rate\n",
    "windowSize = 10 # window size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose embedding approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepWalk\n",
    "\n",
    "rw = DeepWalk(myGraph, walkLength=walkLength, embedDim=embedDim, numbOfWalksPerVertex=numbOfWalksPerVertex, \\\n",
    "                 windowSize=windowSize, lr = lr)\n",
    "\n",
    "#\n",
    "\n",
    "#  Node2Vec\n",
    "\n",
    "# rw = Node2vec(myGraph, walkLength=walkLength, embedDim=embedDim, numbOfWalksPerVertex=numbOfWalksPerVertex, \\\n",
    "#                  windowSize=windowSize, lr=lr, p = 0.5, q = 1)\n",
    "\n",
    "#\n",
    "#  Struc2Vec\n",
    "\n",
    "# rw = Struc2Vec(myGraph, walkLength=walkLength, embedDim=embedDim, numbOfWalksPerVertex=numbOfWalksPerVertex, \\\n",
    "#                   windowSize=windowSize, lr = lr, stay_prob=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Embedding\n",
      "Saving embedding to disk\n"
     ]
    }
   ],
   "source": [
    "model_skip_gram = SkipGramModel(rw.totalNodes, rw.embedDim)\n",
    "print(\"Learning Embedding\")\n",
    "model = rw.learnNodeEmbedding(model_skip_gram)\n",
    "\n",
    "\n",
    "# Save embedding to disk\n",
    "print(\"Saving embedding to disk\")\n",
    "saveEmbedding(data_dir, graph_features, embedding_dir, rw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Embedding for a node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding for a node\n",
      "Node Embedding tensor([ 1.4246, -0.6593, -0.2521])\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating embedding for a node\")\n",
    "node1 = 35\n",
    "node2 = 36\n",
    "\n",
    "# Get Embedding for a node\n",
    "emb = rw.getNodeEmbedding(node1)\n",
    "print(\"Node Embedding\", emb.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Classification on graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d57911d75b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloadEmbedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassify\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "from utils import loadEmbedding, train_test_split, classify, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embedding\n",
    "This is the embedding that we generated previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/cora - copy1.content.embedding\"\n",
    "embedding, labels = loadEmbedding(\"../data/cora - copy1.content.embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Train test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(embedding, labels, test_split = 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learn classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, clf = classify(X_train, y_train, X_test, classifier = \"lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose one of the following classifier for training train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py37_CS224WGraphML",
   "language": "python",
   "name": "py37_cs224wgraphml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
